{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.toptal.com/machine-learning/ensemble-methods-machine-learning\n",
    "\n",
    "https://towardsdatascience.com/lazy-predict-fit-and-evaluate-all-the-models-from-scikit-learn-with-a-single-line-of-code-7fe510c7281\n",
    "\n",
    "https://analyticsindiamag.com/visualizing-and-comparing-ml-models-using-lazypredict/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Part 2 - Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of concurrent jobs\n",
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_ini = np.load('Xtrain_Classification_Part1.npy')\n",
    "Y_train_ini = np.load('Ytrain_Classification_Part1.npy')\n",
    "X_test_out = np.load('Xtest_Classification_Part1.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_ini)\n",
    "scaler.fit(X_test_out)\n",
    "\n",
    "x_train_scaled = scaler.transform(X_train_ini)\n",
    "x_test_out_scaled = scaler.transform(X_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run several models using lazypredict library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuno/anaconda3/envs/AAut/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "100%|██████████| 29/29 [16:21<00:00, 33.84s/it]\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pik\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_train_scaled, Y_train_ini, test_size=.2, random_state=42)\n",
    "\n",
    "# fit all models\n",
    "clf = LazyClassifier(predictions=True)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "with open(r\"lazyModels.pik\", \"wb\") as output_file:\n",
    "    pik.dump(models, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>85.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>107.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>95.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>53.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>31.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>83.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>5.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>28.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>25.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>118.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>6.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>133.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>45.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>19.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>29.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>37.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "SVC                                0.86               0.85     0.85      0.86   \n",
       "NuSVC                              0.85               0.85     0.85      0.85   \n",
       "XGBClassifier                      0.85               0.84     0.84      0.85   \n",
       "LogisticRegression                 0.84               0.84     0.84      0.84   \n",
       "LGBMClassifier                     0.84               0.83     0.83      0.84   \n",
       "Perceptron                         0.83               0.82     0.82      0.83   \n",
       "RidgeClassifierCV                  0.83               0.82     0.82      0.83   \n",
       "CalibratedClassifierCV             0.82               0.81     0.81      0.82   \n",
       "SGDClassifier                      0.82               0.81     0.81      0.82   \n",
       "LinearSVC                          0.81               0.80     0.80      0.81   \n",
       "PassiveAggressiveClassifier        0.80               0.80     0.80      0.80   \n",
       "RandomForestClassifier             0.79               0.79     0.79      0.79   \n",
       "RidgeClassifier                    0.79               0.78     0.78      0.79   \n",
       "AdaBoostClassifier                 0.78               0.78     0.78      0.78   \n",
       "ExtraTreesClassifier               0.78               0.78     0.78      0.78   \n",
       "BaggingClassifier                  0.76               0.77     0.77      0.77   \n",
       "LinearDiscriminantAnalysis         0.77               0.76     0.76      0.77   \n",
       "KNeighborsClassifier               0.73               0.73     0.73      0.73   \n",
       "DecisionTreeClassifier             0.69               0.68     0.68      0.69   \n",
       "GaussianNB                         0.68               0.68     0.68      0.68   \n",
       "NearestCentroid                    0.67               0.68     0.68      0.68   \n",
       "BernoulliNB                        0.65               0.66     0.66      0.65   \n",
       "ExtraTreeClassifier                0.63               0.62     0.62      0.63   \n",
       "DummyClassifier                    0.53               0.52     0.52      0.53   \n",
       "LabelSpreading                     0.45               0.52     0.52      0.30   \n",
       "LabelPropagation                   0.45               0.52     0.52      0.30   \n",
       "QuadraticDiscriminantAnalysis      0.58               0.51     0.51      0.43   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "SVC                                 85.17  \n",
       "NuSVC                              107.81  \n",
       "XGBClassifier                       95.33  \n",
       "LogisticRegression                   4.67  \n",
       "LGBMClassifier                      53.21  \n",
       "Perceptron                           2.19  \n",
       "RidgeClassifierCV                   31.52  \n",
       "CalibratedClassifierCV              83.31  \n",
       "SGDClassifier                        5.19  \n",
       "LinearSVC                           28.88  \n",
       "PassiveAggressiveClassifier          3.68  \n",
       "RandomForestClassifier              25.23  \n",
       "RidgeClassifier                      3.34  \n",
       "AdaBoostClassifier                 118.57  \n",
       "ExtraTreesClassifier                 6.94  \n",
       "BaggingClassifier                  133.00  \n",
       "LinearDiscriminantAnalysis          44.28  \n",
       "KNeighborsClassifier                45.61  \n",
       "DecisionTreeClassifier              19.90  \n",
       "GaussianNB                           1.48  \n",
       "NearestCentroid                      1.22  \n",
       "BernoulliNB                          1.60  \n",
       "ExtraTreeClassifier                  1.15  \n",
       "DummyClassifier                      1.45  \n",
       "LabelSpreading                      29.25  \n",
       "LabelPropagation                     5.32  \n",
       "QuadraticDiscriminantAnalysis       37.50  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all model performances\n",
    "models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cross-validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "# define model evaluation method (repeats k-folds n times, with k-folds=n_splits and n=n_repeats)\n",
    "#cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=random_state)\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 11.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pickle as pik\n",
    "\n",
    "svc_model = SVC(random_state=1)\n",
    "\n",
    "# Tuning: \n",
    "# parameters = {'kernel': ['rbf', 'poly'],\n",
    "#               'C': [0.5, 0.9, 1.0, 10, 100],\n",
    "#               'degree': [1, 2, 3],\n",
    "#               'gamma': [ 0.01, 0.001, 0.0001]}\n",
    "# Result:\n",
    "# best_params_: {'C': 10, 'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "# best_estimator_: SVC(C=10, degree=1, gamma=0.0001, random_state=1)\n",
    "# best_score_: 0.8687789799072643\n",
    "\n",
    "# best_params_: {'C': 30, 'degree': 1, 'gamma': 9.2e-05, 'kernel': 'rbf'}\n",
    "# best_estimator_: SVC(C=30, degree=1, gamma=9.2e-05, random_state=1)\n",
    "# best_score_: 0.8726429675425038\n",
    "\n",
    "parameters = {'kernel': ['rbf'],\n",
    "              'C': [30],\n",
    "              'degree': [1],\n",
    "              'gamma': [0.000092]}\n",
    "\n",
    "svc_grid = GridSearchCV(svc_model, parameters,\n",
    "                        scoring='balanced_accuracy', \n",
    "                        cv=cv, \n",
    "                        verbose=1, \n",
    "                        n_jobs=n_jobs)\n",
    "svc_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"svc_grid.pik\", \"wb\") as output_file:\n",
    "    pik.dump(svc_grid, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'C': 30, 'degree': 1, 'gamma': 9.2e-05, 'kernel': 'rbf'}\n",
      "best_estimator_: SVC(C=30, degree=1, gamma=9.2e-05, random_state=1)\n",
      "best_score_: 0.8693478959787003\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', svc_grid.best_params_)\n",
    "print('best_estimator_:', svc_grid.best_estimator_)\n",
    "print('best_score_:', svc_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SVM NuSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 13.0min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import NuSVC\n",
    "import pickle as pik\n",
    "\n",
    "nusvc_model = NuSVC(random_state=1)\n",
    "\n",
    "parameters = {'kernel': ['rbf'],\n",
    "              'nu': [0.3],\n",
    "              'degree': [1],\n",
    "              'gamma': [0.0001]}\n",
    "\n",
    "nusvc_grid = GridSearchCV(nusvc_model, parameters,\n",
    "                          scoring='balanced_accuracy', \n",
    "                          cv=cv, \n",
    "                          verbose=1, \n",
    "                          n_jobs=n_jobs)\n",
    "nusvc_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"nusvc_grid.pik\", \"wb\") as output_file: \n",
    "    pik.dump(nusvc_grid, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf', 'nu': 0.3}\n",
      "best_estimator_: NuSVC(degree=1, gamma=0.0001, nu=0.3, random_state=1)\n",
      "best_score_: 0.8690068537450027\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', nusvc_grid.best_params_)\n",
    "print('best_estimator_:', nusvc_grid.best_estimator_)\n",
    "print('best_score_:', nusvc_grid.best_score_)\n",
    "\n",
    "# best_params_: {'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf', 'nu': 0.3}\n",
    "# best_estimator_: NuSVC(degree=1, gamma=0.0001, nu=0.3, random_state=1)\n",
    "# best_score_: 0.8680061823802164"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ (muito bom!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 42.7min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle as pik\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=1)\n",
    "\n",
    "parameters = {'objective':['binary:logistic']}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb_model, parameters, scoring='balanced_accuracy', cv=cv, verbose=1, n_jobs=n_jobs)\n",
    "xgb_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"xgb_grid.pik\", \"wb\") as output_file:\n",
    "    pik.dump(xgb_grid, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'objective': 'binary:logistic'}\n",
      "best_estimator_: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "best_score_: 0.8432984173769889\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', xgb_grid.best_params_)\n",
    "print('best_estimator_:', xgb_grid.best_estimator_)\n",
    "print('best_score_:', xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting method with 3 best models using predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = SVC(probability=True, random_state=1)\n",
    "clf2 = NuSVC(probability=True, random_state=1)\n",
    "clf3 = XGBClassifier(objective='binary:logistic', random_state=1)\n",
    "# binary:logistic – logistic regression for binary classification, returns predicted probability (not class)\n",
    "# multi:softmax – multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "# you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "# multi:softprob – same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('svc', clf1), ('nusvc', clf2), ('xgb', clf3)], \n",
    "                         n_jobs=n_jobs, voting='soft')\n",
    "\n",
    "# best_params_: {'C': 30, 'degree': 1, 'gamma': 9.2e-05, 'kernel': 'rbf'}\n",
    "# best_estimator_: SVC(C=30, degree=1, gamma=9.2e-05, random_state=1)\n",
    "# best_score_: 0.8726429675425038\n",
    "\n",
    "# best_params_: {'degree': 1, 'gamma': 0.00015, 'kernel': 'rbf', 'nu': 0.3}\n",
    "# best_estimator_: NuSVC(degree=1, gamma=0.00015, nu=0.3, random_state=1)\n",
    "# best_score_: 0.8700154559505411\n",
    "\n",
    "params = {'svc__C': [30], 'svc__degree':[1], 'svc__gamma': [0.000092], 'svc__kernel':['rbf'],\n",
    "          'nusvc__nu': [0.3], 'nusvc__degree': [1], 'nusvc__gamma': [0.0001]} #'nusvc__gamma': [0.00015]\n",
    "\n",
    "grid2 = GridSearchCV(estimator=eclf2, param_grid=params,\n",
    "                     scoring='balanced_accuracy', \n",
    "                     cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "grid2.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"grid_voting2.pik\", \"wb\") as output_file:\n",
    "    pik.dump(grid2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'nusvc__degree': 1, 'nusvc__gamma': 0.00015, 'nusvc__nu': 0.3, 'svc__C': 30, 'svc__degree': 1, 'svc__gamma': 9.2e-05, 'svc__kernel': 'rbf'}\n",
      "best_estimator_: VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=30, degree=1, gamma=9.2e-05,\n",
      "                                  probability=True, random_state=1)),\n",
      "                             ('nusvc',\n",
      "                              NuSVC(degree=1, gamma=0.00015, nu=0.3,\n",
      "                                    probability=True, random_state=1)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, gamma=None,\n",
      "                                            gpu_id=None, importance_type='gain',\n",
      "                                            intera..._constraints=None,\n",
      "                                            learning_rate=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=100, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=1, reg_alpha=None,\n",
      "                                            reg_lambda=None,\n",
      "                                            scale_pos_weight=None,\n",
      "                                            subsample=None, tree_method=None,\n",
      "                                            validate_parameters=None,\n",
      "                                            verbosity=None))],\n",
      "                 n_jobs=4, voting='soft')\n",
      "best_score_: 0.8701924175026282\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', grid2.best_params_)\n",
    "print('best_estimator_:', grid2.best_estimator_)\n",
    "print('best_score_:', grid2.best_score_)\n",
    "# best_score_: 0.8701924175026282"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output: Best result was achieved with voting for 3 best models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# import pickle as pik\n",
    "\n",
    "# with open(r\"svc_grid.pik\", \"rb\") as f:\n",
    "#     svc_grid = pik.load(f)\n",
    "\n",
    "y_test = grid2.predict(x_test_out_scaled)\n",
    "np.save('Ytest_Classification_Part1.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0af6baf7c8a281cd65d8922d7f2830a6498700536f6f2891fee8a91c6940a690"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('AAut': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
