{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.toptal.com/machine-learning/ensemble-methods-machine-learning\n",
    "\n",
    "https://towardsdatascience.com/lazy-predict-fit-and-evaluate-all-the-models-from-scikit-learn-with-a-single-line-of-code-7fe510c7281\n",
    "\n",
    "https://analyticsindiamag.com/visualizing-and-comparing-ml-models-using-lazypredict/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ini = np.load('Xtrain_Classification_Part1.npy')\n",
    "Y_train_ini = np.load('Ytrain_Classification_Part1.npy')\n",
    "X_test_out = np.load('Xtest_Classification_Part1.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_ini)\n",
    "scaler.fit(X_test_out)\n",
    "\n",
    "x_train_scaled = scaler.transform(X_train_ini)\n",
    "x_test_out_scaled = scaler.transform(X_test_out)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train_scaled, Y_train_ini, test_size=.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [11:20<00:00, 23.46s/it]\n"
     ]
    }
   ],
   "source": [
    "import pickle as pik\n",
    "\n",
    "# fit all models\n",
    "clf = LazyClassifier(predictions=True)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "with open(r\"lazyModels.pik\", \"wb\") as output_file:\n",
    "    pik.dump(models, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>65.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>83.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>79.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>37.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>64.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>17.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>18.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>74.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>97.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>20.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>33.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>14.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>27.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "SVC                                0.86               0.85     0.85      0.86   \n",
       "NuSVC                              0.85               0.85     0.85      0.85   \n",
       "XGBClassifier                      0.85               0.84     0.84      0.85   \n",
       "LogisticRegression                 0.84               0.84     0.84      0.84   \n",
       "LGBMClassifier                     0.84               0.83     0.83      0.84   \n",
       "Perceptron                         0.83               0.82     0.82      0.83   \n",
       "RidgeClassifierCV                  0.83               0.82     0.82      0.83   \n",
       "CalibratedClassifierCV             0.82               0.81     0.81      0.82   \n",
       "SGDClassifier                      0.82               0.81     0.81      0.82   \n",
       "LinearSVC                          0.81               0.80     0.80      0.81   \n",
       "PassiveAggressiveClassifier        0.80               0.80     0.80      0.80   \n",
       "RandomForestClassifier             0.79               0.79     0.79      0.79   \n",
       "RidgeClassifier                    0.79               0.78     0.78      0.79   \n",
       "AdaBoostClassifier                 0.78               0.78     0.78      0.78   \n",
       "ExtraTreesClassifier               0.78               0.78     0.78      0.78   \n",
       "BaggingClassifier                  0.76               0.77     0.77      0.77   \n",
       "LinearDiscriminantAnalysis         0.77               0.76     0.76      0.77   \n",
       "KNeighborsClassifier               0.73               0.73     0.73      0.73   \n",
       "DecisionTreeClassifier             0.69               0.68     0.68      0.69   \n",
       "GaussianNB                         0.68               0.68     0.68      0.68   \n",
       "NearestCentroid                    0.67               0.68     0.68      0.68   \n",
       "BernoulliNB                        0.65               0.66     0.66      0.65   \n",
       "ExtraTreeClassifier                0.63               0.62     0.62      0.63   \n",
       "DummyClassifier                    0.53               0.52     0.52      0.53   \n",
       "LabelSpreading                     0.45               0.52     0.52      0.30   \n",
       "LabelPropagation                   0.45               0.52     0.52      0.30   \n",
       "QuadraticDiscriminantAnalysis      0.58               0.51     0.51      0.43   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "SVC                                 65.44  \n",
       "NuSVC                               83.64  \n",
       "XGBClassifier                       79.02  \n",
       "LogisticRegression                   2.30  \n",
       "LGBMClassifier                      37.61  \n",
       "Perceptron                           1.32  \n",
       "RidgeClassifierCV                   18.30  \n",
       "CalibratedClassifierCV              64.95  \n",
       "SGDClassifier                        3.09  \n",
       "LinearSVC                           17.71  \n",
       "PassiveAggressiveClassifier          1.88  \n",
       "RandomForestClassifier              18.40  \n",
       "RidgeClassifier                      1.70  \n",
       "AdaBoostClassifier                  74.27  \n",
       "ExtraTreesClassifier                 4.84  \n",
       "BaggingClassifier                   97.85  \n",
       "LinearDiscriminantAnalysis          20.84  \n",
       "KNeighborsClassifier                33.49  \n",
       "DecisionTreeClassifier              14.55  \n",
       "GaussianNB                           0.67  \n",
       "NearestCentroid                      0.58  \n",
       "BernoulliNB                          0.77  \n",
       "ExtraTreeClassifier                  0.52  \n",
       "DummyClassifier                      0.51  \n",
       "LabelSpreading                       4.45  \n",
       "LabelPropagation                     3.74  \n",
       "QuadraticDiscriminantAnalysis       27.17  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all model performances\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "# define model evaluation method (repeats k-folds n times, with k-folds=n_splits and n=n_repeats)\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=random_state)\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 20.6min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 91.2min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 208.9min\n",
      "[Parallel(n_jobs=4)]: Done 450 out of 450 | elapsed: 212.2min finished\n"
     ]
    }
   ],
   "source": [
    "#import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(random_state = 1)\n",
    "\n",
    "# Fine tune  for values of alpha\n",
    "# parameters = {'kernel': ['rbf', 'poly'], \n",
    "#               'C': [0.5, 0.9, 1.0, 10, 100],\n",
    "#               'degree': [1, 2, 3],\n",
    "#               'gamma': [ 0.01, 0.001, 0.0001]}\n",
    "# Result:\n",
    "# best_params_: {'C': 10, 'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "# best_estimator_: SVC(C=10, degree=1, gamma=0.0001, random_state=1)\n",
    "# best_score_: 0.8687789799072643\n",
    "\n",
    "\n",
    "parameters = {'kernel': ['rbf'], \n",
    "              'C': [5, 10, 20],\n",
    "              'degree': [1],\n",
    "              'gamma': [ 0.00008, 0.0001, 0.0005]}\n",
    "\n",
    "svc_grid = GridSearchCV(svc_model, parameters, scoring='accuracy', cv = cv, verbose=1, n_jobs=n_jobs)\n",
    "svc_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "#y_pred = svc_model.predict(X_test)\n",
    "#y_pred = svc_grid.predict(x_train_scaled)\n",
    "\n",
    "with open(r\"svc_grid.pik\", \"wb\") as output_file:\n",
    "    pik.dump(svc_grid, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'C': 10, 'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "best_estimator_: SVC(C=10, degree=1, gamma=0.0001, random_state=1)\n",
      "best_score_: 0.8687789799072643\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', svc_grid.best_params_)\n",
    "print('best_estimator_:', svc_grid.best_estimator_)\n",
    "print('best_score_:', svc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svc_model.get_params()\n",
    "\n",
    "# {'C': 1.0,\n",
    "#  'break_ties': False,\n",
    "#  'cache_size': 200,\n",
    "#  'class_weight': None,\n",
    "#  'coef0': 0.0,\n",
    "#  'decision_function_shape': 'ovr',\n",
    "#  'degree': 3,\n",
    "#  'gamma': 'scale',\n",
    "#  'kernel': 'rbf',\n",
    "#  'max_iter': -1,\n",
    "#  'probability': False,\n",
    "#  'random_state': None,\n",
    "#  'shrinking': True,\n",
    "#  'tol': 0.001,\n",
    "#  'verbose': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = SVC(probability=True, random_state=1)\n",
    "clf2 = NuSVC(probability=True, random_state=1)\n",
    "#clf3 = xgb()\n",
    "clf4 = LogisticRegression(max_iter=100, random_state=1)\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    #estimators=[('svc', clf1), ('nusvc', clf2), ('xgb', clf3), ('LogisticRegression', clf4)],\n",
    "    estimators=[('svc', clf1), ('nusvc', clf2), ('LogisticRegression', clf4)],\n",
    "    voting='soft')\n",
    "\n",
    "# params = {'svc__C': [0.5, 0.9, 1.0, 10, 100], 'nusvc__nu': [0.3]}\n",
    "\n",
    "# best_params_: {'nusvc__nu': 0.3, 'svc__C': 10}\n",
    "# best_estimator_: VotingClassifier(estimators=[('svc',\n",
    "#                               SVC(C=10, probability=True, random_state=1)),\n",
    "#                              ('nusvc',\n",
    "#                               NuSVC(nu=0.3, probability=True, random_state=1)),\n",
    "#                              ('LogisticRegression',\n",
    "#                               LogisticRegression(max_iter=200,\n",
    "#                                                  random_state=1))],\n",
    "#                  voting='soft')\n",
    "# best_score_: 0.8700154559505411\n",
    "\n",
    "params = {'svc__C': [10], 'nusvc__nu': [0.3]}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, scoring='accuracy', cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "#y_pred = grid.predict(x_train_scaled)\n",
    "\n",
    "with open(r\"grid_voting.pik\", \"wb\") as output_file:\n",
    "    pik.dump(grid, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'nusvc__nu': 0.3, 'svc__C': 10}\n",
      "best_estimator_: VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=10, probability=True, random_state=1)),\n",
      "                             ('nusvc',\n",
      "                              NuSVC(nu=0.3, probability=True, random_state=1)),\n",
      "                             ('LogisticRegression',\n",
      "                              LogisticRegression(max_iter=200,\n",
      "                                                 random_state=1))],\n",
      "                 voting='soft')\n",
      "best_score_: 0.8700154559505411\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', grid.best_params_)\n",
    "print('best_estimator_:', grid.best_estimator_)\n",
    "print('best_score_:', grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-guide-to-xgboost-for-classification-problems-50f75aac5390\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/ (muito bom!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = SVC(probability=True, random_state=1)\n",
    "clf2 = NuSVC(probability=True, random_state=1)\n",
    "clf3 = XGBClassifier(objective='binary:logistic', random_state=1) \n",
    "# binary:logistic – logistic regression for binary classification, returns predicted probability (not class)\n",
    "# multi:softmax – multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "# you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "# multi:softprob – same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('svc', clf1), ('nusvc', clf2), ('xgb', clf3)], voting='soft')\n",
    "\n",
    "params = {'svc__C': [10], 'nusvc__nu': [0.3]}\n",
    "\n",
    "grid2 = GridSearchCV(estimator=eclf2, param_grid=params, scoring='accuracy', cv=cv, n_jobs=3)\n",
    "\n",
    "grid2.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "#y_pred = grid.predict(x_train_scaled)\n",
    "\n",
    "with open(r\"grid_voting2.pik\", \"wb\") as output_file:\n",
    "    pik.dump(grid2, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'nusvc__nu': 0.3, 'svc__C': 10}\n",
      "best_estimator_: VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=10, probability=True, random_state=1)),\n",
      "                             ('nusvc',\n",
      "                              NuSVC(nu=0.3, probability=True, random_state=1)),\n",
      "                             ('LogisticRegression',\n",
      "                              LogisticRegression(max_iter=200,\n",
      "                                                 random_state=1))],\n",
      "                 voting='soft')\n",
      "best_score_: 0.8700154559505411\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', grid.best_params_)\n",
    "print('best_estimator_:', grid.best_estimator_)\n",
    "print('best_score_:', grid.best_score_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0af6baf7c8a281cd65d8922d7f2830a6498700536f6f2891fee8a91c6940a690"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('AAut': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
