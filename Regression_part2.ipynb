{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression - Part 1 - Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/outlier-detection-in-regression-using-cooks-distance-f5e4954461a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.096306</td>\n",
       "      <td>0.103394</td>\n",
       "      <td>-0.041093</td>\n",
       "      <td>-0.036073</td>\n",
       "      <td>-0.051363</td>\n",
       "      <td>0.175977</td>\n",
       "      <td>-0.002615</td>\n",
       "      <td>0.021736</td>\n",
       "      <td>-0.110863</td>\n",
       "      <td>0.068009</td>\n",
       "      <td>0.058208</td>\n",
       "      <td>0.118485</td>\n",
       "      <td>0.102668</td>\n",
       "      <td>0.040101</td>\n",
       "      <td>0.190118</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>0.066005</td>\n",
       "      <td>-0.040918</td>\n",
       "      <td>0.036576</td>\n",
       "      <td>-0.050878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.947031</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>1.073739</td>\n",
       "      <td>1.007231</td>\n",
       "      <td>0.992275</td>\n",
       "      <td>0.995634</td>\n",
       "      <td>0.924536</td>\n",
       "      <td>1.125673</td>\n",
       "      <td>1.117951</td>\n",
       "      <td>0.937170</td>\n",
       "      <td>1.024629</td>\n",
       "      <td>0.915533</td>\n",
       "      <td>0.929227</td>\n",
       "      <td>0.987411</td>\n",
       "      <td>1.113879</td>\n",
       "      <td>0.981693</td>\n",
       "      <td>0.918804</td>\n",
       "      <td>0.880285</td>\n",
       "      <td>1.065829</td>\n",
       "      <td>1.030510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.237765</td>\n",
       "      <td>-1.694381</td>\n",
       "      <td>-3.433329</td>\n",
       "      <td>-2.851244</td>\n",
       "      <td>-2.558154</td>\n",
       "      <td>-1.788471</td>\n",
       "      <td>-1.965246</td>\n",
       "      <td>-3.310151</td>\n",
       "      <td>-2.953069</td>\n",
       "      <td>-2.286955</td>\n",
       "      <td>-2.027333</td>\n",
       "      <td>-2.017503</td>\n",
       "      <td>-2.584288</td>\n",
       "      <td>-2.372827</td>\n",
       "      <td>-1.984497</td>\n",
       "      <td>-2.286663</td>\n",
       "      <td>-2.240194</td>\n",
       "      <td>-2.006596</td>\n",
       "      <td>-2.560387</td>\n",
       "      <td>-2.830737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.776680</td>\n",
       "      <td>-0.552726</td>\n",
       "      <td>-0.619567</td>\n",
       "      <td>-0.601832</td>\n",
       "      <td>-0.657576</td>\n",
       "      <td>-0.555407</td>\n",
       "      <td>-0.648780</td>\n",
       "      <td>-0.656277</td>\n",
       "      <td>-0.986965</td>\n",
       "      <td>-0.522125</td>\n",
       "      <td>-0.713441</td>\n",
       "      <td>-0.397109</td>\n",
       "      <td>-0.474409</td>\n",
       "      <td>-0.523735</td>\n",
       "      <td>-0.656624</td>\n",
       "      <td>-0.766512</td>\n",
       "      <td>-0.639798</td>\n",
       "      <td>-0.581918</td>\n",
       "      <td>-0.738254</td>\n",
       "      <td>-0.846551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.122215</td>\n",
       "      <td>0.065946</td>\n",
       "      <td>-0.058747</td>\n",
       "      <td>-0.074514</td>\n",
       "      <td>0.045014</td>\n",
       "      <td>0.154525</td>\n",
       "      <td>-0.107089</td>\n",
       "      <td>0.125309</td>\n",
       "      <td>-0.009224</td>\n",
       "      <td>-0.042286</td>\n",
       "      <td>0.074529</td>\n",
       "      <td>0.077402</td>\n",
       "      <td>0.180081</td>\n",
       "      <td>0.025515</td>\n",
       "      <td>0.098189</td>\n",
       "      <td>0.098965</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>-0.017476</td>\n",
       "      <td>0.145513</td>\n",
       "      <td>0.067945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.554967</td>\n",
       "      <td>0.700684</td>\n",
       "      <td>0.631118</td>\n",
       "      <td>0.699446</td>\n",
       "      <td>0.593339</td>\n",
       "      <td>0.780462</td>\n",
       "      <td>0.607118</td>\n",
       "      <td>0.660079</td>\n",
       "      <td>0.704632</td>\n",
       "      <td>0.642025</td>\n",
       "      <td>0.767151</td>\n",
       "      <td>0.709581</td>\n",
       "      <td>0.761737</td>\n",
       "      <td>0.648176</td>\n",
       "      <td>0.886054</td>\n",
       "      <td>0.728499</td>\n",
       "      <td>0.734412</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>0.777096</td>\n",
       "      <td>0.696973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.435484</td>\n",
       "      <td>2.290980</td>\n",
       "      <td>3.020603</td>\n",
       "      <td>2.168331</td>\n",
       "      <td>1.907413</td>\n",
       "      <td>2.934458</td>\n",
       "      <td>2.130421</td>\n",
       "      <td>3.019401</td>\n",
       "      <td>2.074649</td>\n",
       "      <td>2.425904</td>\n",
       "      <td>2.670014</td>\n",
       "      <td>2.175048</td>\n",
       "      <td>2.022771</td>\n",
       "      <td>3.159331</td>\n",
       "      <td>3.076485</td>\n",
       "      <td>2.431136</td>\n",
       "      <td>2.003396</td>\n",
       "      <td>1.909748</td>\n",
       "      <td>2.730227</td>\n",
       "      <td>2.093984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean    -0.096306    0.103394   -0.041093   -0.036073   -0.051363    0.175977   \n",
       "std      0.947031    0.950758    1.073739    1.007231    0.992275    0.995634   \n",
       "min     -2.237765   -1.694381   -3.433329   -2.851244   -2.558154   -1.788471   \n",
       "25%     -0.776680   -0.552726   -0.619567   -0.601832   -0.657576   -0.555407   \n",
       "50%     -0.122215    0.065946   -0.058747   -0.074514    0.045014    0.154525   \n",
       "75%      0.554967    0.700684    0.631118    0.699446    0.593339    0.780462   \n",
       "max      2.435484    2.290980    3.020603    2.168331    1.907413    2.934458   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean    -0.002615    0.021736   -0.110863    0.068009    0.058208    0.118485   \n",
       "std      0.924536    1.125673    1.117951    0.937170    1.024629    0.915533   \n",
       "min     -1.965246   -3.310151   -2.953069   -2.286955   -2.027333   -2.017503   \n",
       "25%     -0.648780   -0.656277   -0.986965   -0.522125   -0.713441   -0.397109   \n",
       "50%     -0.107089    0.125309   -0.009224   -0.042286    0.074529    0.077402   \n",
       "75%      0.607118    0.660079    0.704632    0.642025    0.767151    0.709581   \n",
       "max      2.130421    3.019401    2.074649    2.425904    2.670014    2.175048   \n",
       "\n",
       "               12          13          14          15          16          17  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean     0.102668    0.040101    0.190118    0.014326    0.066005   -0.040918   \n",
       "std      0.929227    0.987411    1.113879    0.981693    0.918804    0.880285   \n",
       "min     -2.584288   -2.372827   -1.984497   -2.286663   -2.240194   -2.006596   \n",
       "25%     -0.474409   -0.523735   -0.656624   -0.766512   -0.639798   -0.581918   \n",
       "50%      0.180081    0.025515    0.098189    0.098965    0.130909   -0.017476   \n",
       "75%      0.761737    0.648176    0.886054    0.728499    0.734412    0.458716   \n",
       "max      2.022771    3.159331    3.076485    2.431136    2.003396    1.909748   \n",
       "\n",
       "               18          19  \n",
       "count  100.000000  100.000000  \n",
       "mean     0.036576   -0.050878  \n",
       "std      1.065829    1.030510  \n",
       "min     -2.560387   -2.830737  \n",
       "25%     -0.738254   -0.846551  \n",
       "50%      0.145513    0.067945  \n",
       "75%      0.777096    0.696973  \n",
       "max      2.730227    2.093984  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_train = np.load('Xtrain_Regression_Part2.npy')\n",
    "Y_train = np.load('Ytrain_Regression_Part2.npy')\n",
    "\n",
    "X_test = np.load('Xtest_Regression_Part2.npy')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(X_train)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the boxplots to visualize the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "# Creating dataset\n",
    "#np.random.seed(10)\n",
    "#data = X_train\n",
    " \n",
    "#fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "# Creating plot\n",
    "#plt.boxplot(data)\n",
    " \n",
    "# show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.665335e-18</td>\n",
       "      <td>-2.040035e-17</td>\n",
       "      <td>2.220446e-18</td>\n",
       "      <td>-3.996803e-17</td>\n",
       "      <td>2.664535e-17</td>\n",
       "      <td>1.498801e-17</td>\n",
       "      <td>-3.164136e-17</td>\n",
       "      <td>2.220446e-17</td>\n",
       "      <td>-1.554312e-17</td>\n",
       "      <td>1.665335e-18</td>\n",
       "      <td>5.329071e-17</td>\n",
       "      <td>-4.884981e-17</td>\n",
       "      <td>2.220446e-18</td>\n",
       "      <td>-3.441691e-17</td>\n",
       "      <td>-2.775558e-18</td>\n",
       "      <td>2.109424e-17</td>\n",
       "      <td>-3.552714e-17</td>\n",
       "      <td>5.551115e-18</td>\n",
       "      <td>-2.664535e-17</td>\n",
       "      <td>-1.609823e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "      <td>1.005038e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.272625e+00</td>\n",
       "      <td>-1.900413e+00</td>\n",
       "      <td>-3.175190e+00</td>\n",
       "      <td>-2.809041e+00</td>\n",
       "      <td>-2.539035e+00</td>\n",
       "      <td>-1.983001e+00</td>\n",
       "      <td>-2.133523e+00</td>\n",
       "      <td>-2.974817e+00</td>\n",
       "      <td>-2.555143e+00</td>\n",
       "      <td>-2.525505e+00</td>\n",
       "      <td>-2.045665e+00</td>\n",
       "      <td>-2.344807e+00</td>\n",
       "      <td>-2.906169e+00</td>\n",
       "      <td>-2.456001e+00</td>\n",
       "      <td>-1.962125e+00</td>\n",
       "      <td>-2.355707e+00</td>\n",
       "      <td>-2.522646e+00</td>\n",
       "      <td>-2.244252e+00</td>\n",
       "      <td>-2.448842e+00</td>\n",
       "      <td>-2.711147e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.220468e-01</td>\n",
       "      <td>-6.935783e-01</td>\n",
       "      <td>-5.414616e-01</td>\n",
       "      <td>-5.645269e-01</td>\n",
       "      <td>-6.140108e-01</td>\n",
       "      <td>-7.382908e-01</td>\n",
       "      <td>-7.024283e-01</td>\n",
       "      <td>-6.053525e-01</td>\n",
       "      <td>-7.876155e-01</td>\n",
       "      <td>-6.328700e-01</td>\n",
       "      <td>-7.568947e-01</td>\n",
       "      <td>-5.659994e-01</td>\n",
       "      <td>-6.241577e-01</td>\n",
       "      <td>-5.739008e-01</td>\n",
       "      <td>-7.640036e-01</td>\n",
       "      <td>-7.994066e-01</td>\n",
       "      <td>-7.720458e-01</td>\n",
       "      <td>-6.176693e-01</td>\n",
       "      <td>-7.306359e-01</td>\n",
       "      <td>-7.760052e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.749618e-02</td>\n",
       "      <td>-3.958602e-02</td>\n",
       "      <td>-1.652510e-02</td>\n",
       "      <td>-3.835683e-02</td>\n",
       "      <td>9.761596e-02</td>\n",
       "      <td>-2.165421e-02</td>\n",
       "      <td>-1.135712e-01</td>\n",
       "      <td>9.247274e-02</td>\n",
       "      <td>9.137390e-02</td>\n",
       "      <td>-1.182818e-01</td>\n",
       "      <td>1.600933e-02</td>\n",
       "      <td>-4.509908e-02</td>\n",
       "      <td>8.372855e-02</td>\n",
       "      <td>-1.484607e-02</td>\n",
       "      <td>-8.294597e-02</td>\n",
       "      <td>8.665184e-02</td>\n",
       "      <td>7.099593e-02</td>\n",
       "      <td>2.676489e-02</td>\n",
       "      <td>1.027237e-01</td>\n",
       "      <td>1.158859e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.911643e-01</td>\n",
       "      <td>6.313902e-01</td>\n",
       "      <td>6.292004e-01</td>\n",
       "      <td>7.339178e-01</td>\n",
       "      <td>6.529941e-01</td>\n",
       "      <td>6.101946e-01</td>\n",
       "      <td>6.628241e-01</td>\n",
       "      <td>5.699330e-01</td>\n",
       "      <td>7.331304e-01</td>\n",
       "      <td>6.155852e-01</td>\n",
       "      <td>6.953877e-01</td>\n",
       "      <td>6.488834e-01</td>\n",
       "      <td>7.128388e-01</td>\n",
       "      <td>6.189305e-01</td>\n",
       "      <td>6.279327e-01</td>\n",
       "      <td>7.311566e-01</td>\n",
       "      <td>7.311402e-01</td>\n",
       "      <td>5.704427e-01</td>\n",
       "      <td>6.982838e-01</td>\n",
       "      <td>7.293657e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.686865e+00</td>\n",
       "      <td>2.312479e+00</td>\n",
       "      <td>2.865798e+00</td>\n",
       "      <td>2.199604e+00</td>\n",
       "      <td>1.983970e+00</td>\n",
       "      <td>2.784534e+00</td>\n",
       "      <td>2.318765e+00</td>\n",
       "      <td>2.676412e+00</td>\n",
       "      <td>1.964776e+00</td>\n",
       "      <td>2.528649e+00</td>\n",
       "      <td>2.561867e+00</td>\n",
       "      <td>2.257618e+00</td>\n",
       "      <td>2.076754e+00</td>\n",
       "      <td>3.174911e+00</td>\n",
       "      <td>2.604329e+00</td>\n",
       "      <td>2.474283e+00</td>\n",
       "      <td>2.119224e+00</td>\n",
       "      <td>2.227114e+00</td>\n",
       "      <td>2.540015e+00</td>\n",
       "      <td>2.091846e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   1.665335e-18 -2.040035e-17  2.220446e-18 -3.996803e-17  2.664535e-17   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -2.272625e+00 -1.900413e+00 -3.175190e+00 -2.809041e+00 -2.539035e+00   \n",
       "25%   -7.220468e-01 -6.935783e-01 -5.414616e-01 -5.645269e-01 -6.140108e-01   \n",
       "50%   -2.749618e-02 -3.958602e-02 -1.652510e-02 -3.835683e-02  9.761596e-02   \n",
       "75%    6.911643e-01  6.313902e-01  6.292004e-01  7.339178e-01  6.529941e-01   \n",
       "max    2.686865e+00  2.312479e+00  2.865798e+00  2.199604e+00  1.983970e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   1.498801e-17 -3.164136e-17  2.220446e-17 -1.554312e-17  1.665335e-18   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -1.983001e+00 -2.133523e+00 -2.974817e+00 -2.555143e+00 -2.525505e+00   \n",
       "25%   -7.382908e-01 -7.024283e-01 -6.053525e-01 -7.876155e-01 -6.328700e-01   \n",
       "50%   -2.165421e-02 -1.135712e-01  9.247274e-02  9.137390e-02 -1.182818e-01   \n",
       "75%    6.101946e-01  6.628241e-01  5.699330e-01  7.331304e-01  6.155852e-01   \n",
       "max    2.784534e+00  2.318765e+00  2.676412e+00  1.964776e+00  2.528649e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
       "mean   5.329071e-17 -4.884981e-17  2.220446e-18 -3.441691e-17 -2.775558e-18   \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00   \n",
       "min   -2.045665e+00 -2.344807e+00 -2.906169e+00 -2.456001e+00 -1.962125e+00   \n",
       "25%   -7.568947e-01 -5.659994e-01 -6.241577e-01 -5.739008e-01 -7.640036e-01   \n",
       "50%    1.600933e-02 -4.509908e-02  8.372855e-02 -1.484607e-02 -8.294597e-02   \n",
       "75%    6.953877e-01  6.488834e-01  7.128388e-01  6.189305e-01  6.279327e-01   \n",
       "max    2.561867e+00  2.257618e+00  2.076754e+00  3.174911e+00  2.604329e+00   \n",
       "\n",
       "                 15            16            17            18            19  \n",
       "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  \n",
       "mean   2.109424e-17 -3.552714e-17  5.551115e-18 -2.664535e-17 -1.609823e-17  \n",
       "std    1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  1.005038e+00  \n",
       "min   -2.355707e+00 -2.522646e+00 -2.244252e+00 -2.448842e+00 -2.711147e+00  \n",
       "25%   -7.994066e-01 -7.720458e-01 -6.176693e-01 -7.306359e-01 -7.760052e-01  \n",
       "50%    8.665184e-02  7.099593e-02  2.676489e-02  1.027237e-01  1.158859e-01  \n",
       "75%    7.311566e-01  7.311402e-01  5.704427e-01  6.982838e-01  7.293657e-01  \n",
       "max    2.474283e+00  2.119224e+00  2.227114e+00  2.540015e+00  2.091846e+00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "#df1 = pd.DataFrame(x_train_scaled)\n",
    "#df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    " \n",
    "# Creating dataset\n",
    "np.random.seed(10)\n",
    "data = x_train_scaled\n",
    " \n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "# Creating plot\n",
    "plt.boxplot(data)\n",
    " \n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cross-validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "round_digits = 7\n",
    "random_state = 1\n",
    "#random_state = None\n",
    "\n",
    "# define model evaluation method (repeats k-folds n times, with k-folds=n_splits and n=n_repeats)\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef.: [[ 0.86476382 -0.0782559  -0.220897    0.08666146 -1.21094778 -0.74048044\n",
      "  -0.03217447  0.02262833  1.27329019 -0.02962069 -0.0570129   1.25677608\n",
      "   0.10617605 -0.01549097  0.31303189  0.44268159  0.55151824 -0.33164366\n",
      "   0.76961722  0.46796429]]\n",
      "Intercept.: [-0.02584225]\n",
      "MSE: 2.0650802   std: 3.8182864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import absolute\n",
    "\n",
    "# Ordinary least squares Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train_scaled, Y_train)\n",
    "\n",
    "# Evaluate the model with cross-validation \n",
    "score = cross_val_score(lr, x_train_scaled, Y_train, cv=cv, scoring='neg_mean_squared_error')\n",
    "\n",
    "OLS_MSE = round(absolute(score.mean()), round_digits)\n",
    "\n",
    "print('Coef.:', lr.coef_)\n",
    "print('Intercept.:', lr.intercept_)\n",
    "print(\"MSE:\", OLS_MSE, '  std:', round(score.std(), round_digits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regularization model with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 99 candidates, totalling 2970 fits\n",
      "Lasso Coef.: [ 0.82311757 -0.06549022 -0.16334619  0.         -1.19733754 -0.69212358\n",
      " -0.01535404  0.          1.2345708  -0.         -0.03616455  1.19608079\n",
      "  0.04837262 -0.          0.26817516  0.38851657  0.51089009 -0.27449747\n",
      "  0.73694602  0.39726821]\n",
      "Lasso Intercept: [-0.02584225]\n",
      "Lasso best params: {'alpha': 0.037000000000000005}\n",
      "Lasso MSE: 1.9944577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "# 1st try for tunning values of alpha \n",
    "# parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]}\n",
    "# Results:\n",
    "# Lasso best params: {'alpha': 0.01}\n",
    "# Lasso MSE: \n",
    "\n",
    "# Fine tune  for values of alpha\n",
    "parameters = {'alpha': np.arange(0.001, 0.1, 0.001)}\n",
    "\n",
    "lasso_lr = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv = cv, verbose=1)\n",
    "lasso_lr.fit(x_train_scaled, Y_train)\n",
    "\n",
    "print('Lasso Coef.:', lasso_lr.best_estimator_.coef_)\n",
    "print('Lasso Intercept:', lasso_lr.best_estimator_.intercept_)\n",
    "\n",
    "print('Lasso best params:', lasso_lr.best_params_ )\n",
    "\n",
    "lasso_MSE = round(np.absolute(lasso_lr.best_score_), round_digits)\n",
    "print('Lasso MSE:', lasso_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor, LinearRegression ,Ridge ,SGDRegressor,  ElasticNet, PassiveAggressiveRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from sklearn.impute import SimpleImputer # imputer for missing values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "#RawData=pd.read_excel(\"Outlier Regression.xlsx\")\n",
    "#Data=RawData.drop([\"Target\"], axis=1)\n",
    "\n",
    "\n",
    "# Data = pd.DataFrame(x_train_scaled)\n",
    "# sns.set(rc={'figure.figsize':(17,17)})\n",
    "# sns.heatmap(Data.corr(), cmap=\"YlGnBu\", annot=True)\n",
    "# plt.show()\n",
    "# sns.set(rc={'figure.figsize':(8,8)})\n",
    "# sns.boxplot(data=Data, orient=\"h\",palette=\"Set2\")\n",
    "# plt.show()\n",
    "\n",
    "#print (Data.info())\n",
    "#print(Data.describe())\n",
    "#imputer = SimpleImputer(strategy=\"mean\")\n",
    "#imputer.fit(Data)\n",
    "#TransformData = imputer.transform(Data)\n",
    "#X=pd.DataFrame(TransformData, columns=Data.columns)\n",
    "#print (X.info())\n",
    "#vif = pd.DataFrame()\n",
    "#vif[\"features\"] = X.columns\n",
    "#vif[\"vif_Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "#print('VIF: ', vif)\n",
    "#y=pd.DataFrame(Y_train)\n",
    "y=Y_train\n",
    "Huber = HuberRegressor()\n",
    "Linear = LinearRegression()\n",
    "SGD= SGDRegressor()\n",
    "Ridge=Ridge()\n",
    "SVR=LinearSVR()\n",
    "Elastic=ElasticNet(random_state=0)\n",
    "PassiveAggressiveRegressor= PassiveAggressiveRegressor()\n",
    "estimators = [Linear,SGD,SVR,Huber, Ridge, Elastic,PassiveAggressiveRegressor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LinearRegression(), SGDRegressor(), LinearSVR(), HuberRegressor(), Ridge(), ElasticNet(random_state=0), PassiveAggressiveRegressor()]\n"
     ]
    }
   ],
   "source": [
    "#print(type(Data))\n",
    "#print(Data.shape)\n",
    "#print(X.shape)\n",
    "\n",
    "print (estimators)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in estimators:\n",
    "    reg= i.fit(X_train, Y_train)\n",
    "    \n",
    "    print(str(i)+\" Coefficients:\", np.round(i.coef_,2))\n",
    "    print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://machinelearningmastery.com/robust-regression-for-machine-learning-in-python/\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_huber_vs_ridge.html\n",
    "\n",
    "\n",
    "\n",
    "# Multivariate outliers removal\n",
    "https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 1.671 (4.101)\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from numpy import arange\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# set the seed\n",
    "seed(1) \n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "\t# define model evaluation method\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\t# force scores to be positive\n",
    "\treturn absolute(scores)\n",
    " \n",
    " \n",
    "# load dataset\n",
    "#X, y = get_dataset()\n",
    "\n",
    "# define the model\n",
    "model = HuberRegressor()\n",
    "\n",
    "# evaluate model\n",
    "#results = evaluate_model(X_train, Y_train, model)\n",
    "results = evaluate_model(X_train, Y_train.ravel(), model)\n",
    "\n",
    "print('Mean MSE: %.3f (%.3f)' % (mean(results), std(results)))\n",
    "# plot the line of best fit\n",
    "#plot_best_fit(X, y, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_train.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression ,Ridge ,Lasso, HuberRegressor, RANSACRegressor, TheilSenRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "Linear = LinearRegression()\n",
    "Ridge=Ridge()\n",
    "Lasso=Lasso()\n",
    "Huber = HuberRegressor()\n",
    "Ransac=RANSACRegressor()\n",
    "Theil=TheilSenRegressor()\n",
    "estimators = [Linear, Ridge, Lasso, Huber, Ransac, Theil]\n",
    "\n",
    "# evaluate a model\n",
    "def evaluate_model(X, y, model):\n",
    "\t# define model evaluation method\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\t# force scores to be positive\n",
    "\treturn absolute(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LinearRegression()\n",
      "Mean MSE (std): 2.065 (3.818)\n",
      "Model:  Ridge()\n",
      "Mean MSE (std): 2.050 (3.789)\n",
      "Model:  Lasso()\n",
      "Mean MSE (std): 7.981 (3.841)\n",
      "Model:  HuberRegressor()\n",
      "Mean MSE (std): 1.671 (4.101)\n",
      "Model:  RANSACRegressor()\n",
      "Mean MSE (std): 1.660 (4.076)\n",
      "Model:  TheilSenRegressor(max_subpopulation=10000)\n",
      "Mean MSE (std): 1.653 (4.056)\n"
     ]
    }
   ],
   "source": [
    "for model in estimators:\n",
    "    print('Model: ', model)\n",
    "    results = evaluate_model(X_train, Y_train.ravel(), model)\n",
    "    print('Mean MSE (std): %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0af6baf7c8a281cd65d8922d7f2830a6498700536f6f2891fee8a91c6940a690"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('AAut': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
