{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Part 2 - Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of concurrent jobs\n",
    "n_jobs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_ini = np.load('Xtrain_Classification_Part1.npy')\n",
    "Y_train_ini = np.load('Ytrain_Classification_Part1.npy')\n",
    "X_test_out = np.load('Xtest_Classification_Part1.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_ini)\n",
    "scaler.fit(X_test_out)\n",
    "\n",
    "x_train_scaled = scaler.transform(X_train_ini)\n",
    "x_test_out_scaled = scaler.transform(X_test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run several models using lazypredict library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuno/anaconda3/envs/AAut/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "100%|██████████| 29/29 [11:55<00:00, 24.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pik\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_train_scaled, Y_train_ini, test_size=.2, random_state=42)\n",
    "\n",
    "# fit all models\n",
    "clf = LazyClassifier(predictions=True)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "with open(r\"lazyModels.pik\", \"wb\") as output_file:\n",
    "    pik.dump(models, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>67.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>84.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>85.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>43.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>25.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>67.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "      <td>17.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>18.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>78.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>100.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.77</td>\n",
       "      <td>20.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>33.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>14.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>28.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "SVC                                0.86               0.85     0.85      0.86   \n",
       "NuSVC                              0.85               0.85     0.85      0.85   \n",
       "XGBClassifier                      0.85               0.84     0.84      0.85   \n",
       "LogisticRegression                 0.84               0.84     0.84      0.84   \n",
       "LGBMClassifier                     0.84               0.83     0.83      0.84   \n",
       "Perceptron                         0.83               0.82     0.82      0.83   \n",
       "RidgeClassifierCV                  0.83               0.82     0.82      0.83   \n",
       "CalibratedClassifierCV             0.82               0.81     0.81      0.82   \n",
       "SGDClassifier                      0.82               0.81     0.81      0.82   \n",
       "LinearSVC                          0.81               0.80     0.80      0.81   \n",
       "PassiveAggressiveClassifier        0.80               0.80     0.80      0.80   \n",
       "RandomForestClassifier             0.79               0.79     0.79      0.79   \n",
       "RidgeClassifier                    0.79               0.78     0.78      0.79   \n",
       "AdaBoostClassifier                 0.78               0.78     0.78      0.78   \n",
       "ExtraTreesClassifier               0.78               0.78     0.78      0.78   \n",
       "BaggingClassifier                  0.76               0.77     0.77      0.77   \n",
       "LinearDiscriminantAnalysis         0.77               0.76     0.76      0.77   \n",
       "KNeighborsClassifier               0.73               0.73     0.73      0.73   \n",
       "DecisionTreeClassifier             0.69               0.68     0.68      0.69   \n",
       "GaussianNB                         0.68               0.68     0.68      0.68   \n",
       "NearestCentroid                    0.67               0.68     0.68      0.68   \n",
       "BernoulliNB                        0.65               0.66     0.66      0.65   \n",
       "ExtraTreeClassifier                0.63               0.62     0.62      0.63   \n",
       "DummyClassifier                    0.53               0.52     0.52      0.53   \n",
       "LabelSpreading                     0.45               0.52     0.52      0.30   \n",
       "LabelPropagation                   0.45               0.52     0.52      0.30   \n",
       "QuadraticDiscriminantAnalysis      0.58               0.51     0.51      0.43   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "SVC                                 67.05  \n",
       "NuSVC                               84.02  \n",
       "XGBClassifier                       85.56  \n",
       "LogisticRegression                   2.90  \n",
       "LGBMClassifier                      43.90  \n",
       "Perceptron                           1.34  \n",
       "RidgeClassifierCV                   25.58  \n",
       "CalibratedClassifierCV              67.77  \n",
       "SGDClassifier                        3.20  \n",
       "LinearSVC                           17.83  \n",
       "PassiveAggressiveClassifier          1.98  \n",
       "RandomForestClassifier              18.71  \n",
       "RidgeClassifier                      2.39  \n",
       "AdaBoostClassifier                  78.70  \n",
       "ExtraTreesClassifier                 4.79  \n",
       "BaggingClassifier                  100.99  \n",
       "LinearDiscriminantAnalysis          20.09  \n",
       "KNeighborsClassifier                33.62  \n",
       "DecisionTreeClassifier              14.57  \n",
       "GaussianNB                           0.67  \n",
       "NearestCentroid                      0.59  \n",
       "BernoulliNB                          0.78  \n",
       "ExtraTreeClassifier                  0.56  \n",
       "DummyClassifier                      0.50  \n",
       "LabelSpreading                       4.55  \n",
       "LabelPropagation                     3.82  \n",
       "QuadraticDiscriminantAnalysis       28.86  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all model performances\n",
    "models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define cross-validation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "random_state = 1\n",
    "\n",
    "# define model evaluation method (repeats k-folds n times, with k-folds=n_splits and n=n_repeats)\n",
    "#cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=random_state)\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 10.6min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pickle as pik\n",
    "\n",
    "svc_model = SVC(random_state=1)\n",
    "\n",
    "# Tuning: \n",
    "# parameters = {'kernel': ['rbf', 'poly'],\n",
    "#               'C': [0.5, 0.9, 1.0, 10, 100],\n",
    "#               'degree': [1, 2, 3],\n",
    "#               'gamma': [ 0.01, 0.001, 0.0001]}\n",
    "# Result:\n",
    "# best_params_: {'C': 10, 'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "# best_score_: 0.8687789799072643\n",
    "\n",
    "# After tuning with scoring='accuracy'\n",
    "# best_params_: {'C': 30, 'degree': 1, 'gamma': 9.2e-05, 'kernel': 'rbf'}\n",
    "# best_score_: 0.8726429675425038\n",
    "\n",
    "parameters = {'kernel': ['rbf'],\n",
    "              'C': [30],\n",
    "              'degree': [1],\n",
    "              'gamma': [0.000092]}\n",
    "\n",
    "# scoring='balanced_accuracy'\n",
    "svc_grid = GridSearchCV(svc_model, parameters,\n",
    "                        scoring='balanced_accuracy', \n",
    "                        cv=cv, \n",
    "                        verbose=1, \n",
    "                        n_jobs=n_jobs)\n",
    "svc_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"svc_grid.pik\", \"wb\") as output_file:\n",
    "    pik.dump(svc_grid, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'C': 30, 'degree': 1, 'gamma': 9.2e-05, 'kernel': 'rbf'}\n",
      "best_estimator_: SVC(C=30, degree=1, gamma=9.2e-05, random_state=1)\n",
      "best_score_: 0.8693478959787003\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', svc_grid.best_params_)\n",
    "print('best_estimator_:', svc_grid.best_estimator_)\n",
    "print('best_score_:', svc_grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run SVM NuSVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 13.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import NuSVC\n",
    "import pickle as pik\n",
    "\n",
    "nusvc_model = NuSVC(random_state=1)\n",
    "\n",
    "# Parameters after tuning\n",
    "parameters = {'kernel': ['rbf'],\n",
    "              'nu': [0.3],\n",
    "              'degree': [1],\n",
    "              'gamma': [0.0001]}\n",
    "\n",
    "# scoring='balanced_accuracy'\n",
    "nusvc_grid = GridSearchCV(nusvc_model, parameters,\n",
    "                          scoring='balanced_accuracy', \n",
    "                          cv=cv, \n",
    "                          verbose=1, \n",
    "                          n_jobs=n_jobs)\n",
    "nusvc_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"nusvc_grid.pik\", \"wb\") as output_file: \n",
    "    pik.dump(nusvc_grid, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'degree': 1, 'gamma': 0.0001, 'kernel': 'rbf', 'nu': 0.3}\n",
      "best_estimator_: NuSVC(degree=1, gamma=0.0001, nu=0.3, random_state=1)\n",
      "best_score_: 0.8690068537450027\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', nusvc_grid.best_params_)\n",
    "print('best_estimator_:', nusvc_grid.best_estimator_)\n",
    "print('best_score_:', nusvc_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed: 42.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import pickle as pik\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=1)\n",
    "\n",
    "parameters = {'objective':['binary:logistic']}\n",
    "\n",
    "# scoring='balanced_accuracy'\n",
    "xgb_grid = GridSearchCV(xgb_model, parameters, scoring='balanced_accuracy', cv=cv, verbose=1, n_jobs=n_jobs)\n",
    "xgb_grid.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"xgb_grid.pik\", \"wb\") as output_file:\n",
    "    pik.dump(xgb_grid, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'objective': 'binary:logistic'}\n",
      "best_estimator_: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "best_score_: 0.8432984173769889\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', xgb_grid.best_params_)\n",
    "print('best_estimator_:', xgb_grid.best_estimator_)\n",
    "print('best_score_:', xgb_grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting method with 3 best models using predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = SVC(probability=True, random_state=1)\n",
    "clf2 = NuSVC(probability=True, random_state=1)\n",
    "\n",
    "# binary:logistic – logistic regression for binary classification, returns predicted probability (not class)\n",
    "clf3 = XGBClassifier(objective='binary:logistic', random_state=1)\n",
    "\n",
    "eclf2 = VotingClassifier(estimators=[('svc', clf1), ('nusvc', clf2), ('xgb', clf3)], \n",
    "                         n_jobs=n_jobs, voting='soft')\n",
    "\n",
    "# best_params_: {'C': 30, 'degree': 1, 'gamma': 9.2e-05, 'kernel': 'rbf'}\n",
    "# best_estimator_: SVC(C=30, degree=1, gamma=9.2e-05, random_state=1)\n",
    "# best_score_: 0.8726429675425038\n",
    "\n",
    "# best_params_: {'degree': 1, 'gamma': 0.00015, 'kernel': 'rbf', 'nu': 0.3}\n",
    "# best_estimator_: NuSVC(degree=1, gamma=0.00015, nu=0.3, random_state=1)\n",
    "# best_score_: 0.8700154559505411\n",
    "\n",
    "params = {'svc__C': [30], 'svc__degree':[1], 'svc__gamma': [0.000092], 'svc__kernel':['rbf'],\n",
    "          'nusvc__nu': [0.3], 'nusvc__degree': [1], 'nusvc__gamma': [0.0001]} #'nusvc__gamma': [0.00015]\n",
    "\n",
    "# scoring='balanced_accuracy'\n",
    "grid2 = GridSearchCV(estimator=eclf2, param_grid=params,\n",
    "                     scoring='balanced_accuracy', \n",
    "                     cv=cv, n_jobs=n_jobs)\n",
    "\n",
    "grid2.fit(x_train_scaled, Y_train_ini)\n",
    "\n",
    "with open(r\"grid_voting2.pik\", \"wb\") as output_file:\n",
    "    pik.dump(grid2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params_: {'nusvc__degree': 1, 'nusvc__gamma': 0.0001, 'nusvc__nu': 0.3, 'svc__C': 30, 'svc__degree': 1, 'svc__gamma': 9.2e-05, 'svc__kernel': 'rbf'}\n",
      "best_estimator_: VotingClassifier(estimators=[('svc',\n",
      "                              SVC(C=30, degree=1, gamma=9.2e-05,\n",
      "                                  probability=True, random_state=1)),\n",
      "                             ('nusvc',\n",
      "                              NuSVC(degree=1, gamma=0.0001, nu=0.3,\n",
      "                                    probability=True, random_state=1)),\n",
      "                             ('xgb',\n",
      "                              XGBClassifier(base_score=None, booster=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=None, gamma=None,\n",
      "                                            gpu_id=None, importance_type='gain',\n",
      "                                            interac..._constraints=None,\n",
      "                                            learning_rate=None,\n",
      "                                            max_delta_step=None, max_depth=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=100, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=1, reg_alpha=None,\n",
      "                                            reg_lambda=None,\n",
      "                                            scale_pos_weight=None,\n",
      "                                            subsample=None, tree_method=None,\n",
      "                                            validate_parameters=None,\n",
      "                                            verbosity=None))],\n",
      "                 n_jobs=4, voting='soft')\n",
      "best_score_: 0.870280348901101\n"
     ]
    }
   ],
   "source": [
    "print('best_params_:', grid2.best_params_)\n",
    "print('best_estimator_:', grid2.best_estimator_)\n",
    "print('best_score_:', grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output: Best result was achieved with voting for 3 best models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# import pickle as pik\n",
    "# with open(r\"svc_grid.pik\", \"rb\") as f:\n",
    "#     svc_grid = pik.load(f)\n",
    "\n",
    "y_test = grid2.predict(x_test_out_scaled)\n",
    "np.save('Ytest_Classification_Part1.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0af6baf7c8a281cd65d8922d7f2830a6498700536f6f2891fee8a91c6940a690"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('AAut': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
